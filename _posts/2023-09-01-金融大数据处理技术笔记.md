---
layout: post
title: 金融大数据处理技术笔记
subtitle: FBDP
categories: LectureNotes
tags: FBDP
banner: "/assets/images/banners/toho.jpeg"
---

## CH1 大数据

### 三次信息化浪潮

![image-20230918202007883](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202007883.png)

### 四种研究范式

![image-20230918202055346](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202055346.png)

### 大数据

#### 定义

大数据意指一个超大的、难以用现有常规的数据库管理技术和工具 

处理的数据集。

#### 5V特征

* Volume（大体量）：即可从数百TB到数十数百PB，甚至EB的规模

* Variety（多样性）：即大数据包括各种格式和形态的数据
* Velocity（时效性）：即很多大数据需要在一定的时间限度下得到及时处理
* Veracity（准确性）：即处理的结果要保证一定的准确性
* Value（大价值）：即大数据包含很多深度的价值，大数据分析挖掘和利用将带来巨大的商业价值

#### 结构化/半结构化/非结构化

* 结构化数据：结构化数据是指在预定义的数据模型中组织的数据，通常存储在关系数据库中。它们有严格的格式和规则，例如行和列的表格。
* 半结构化数据：半结构化数据介于结构化数据和非结构化数据之间。它们没有严格的数据模型，但有某种形式的结构。例如JSON就是一个常见的数据格式，它有一些形式的规范（例如分隔），但可以存储数值，字符串等多种类型的元素。
* 非结构化数据：非结构化数据是没有特定结构的数据。这种数据类型包括文本、视频、音频、社交媒体发布等。

#### 不同类型

![image-20230918202424665](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202424665.png)

#### 大数据问题的特点和研究原则

##### 基本特点

* 大数据来自应用行业，**具有极强的行业应用需求特性**
* **数据规模极大**，达到PB甚至EB量级，超过任何传统数据库系统的处理能力
* 大数据处理给传统计算技术带来极大挑战，大多数传统算法在面向大数据处理时都面临问题，需要重写

##### 基本原则

* 应用需求为导向：以行业应用问题和需求为出发点
* 领域交叉为桥梁：行业、IT产业、学术界协同
* 计算技术为支撑：研究解决涉及的计算技术问题

#### 大数据的引擎

是软件，软件改变世界！

#### 大数据研究基本目标

以有效的信息技术手段和计算方法，获取、处理和分析各类应用行

业的大数据，发现和提取数据的内在价值，为行业提供高附加值的

应用和服务。

* 技术手段：信息技术和计算方法

* 核心目标：价值发现
* 效益目标：形成高附加值行业应用

#### 大数据研究的挑战和基本途径

##### 挑战

* 数据规模导致难以应付的存储量
* 数据规模导致传统算法失效
* 大数据复杂的数据关联性导致高复杂度的计算

##### 基本途径

* 寻找新算法降低计算复杂度
* 降低大数据尺度，寻找数据尺度无关算法
* 大数据并行化处理

#### 大数据典型和热点技术问题

![image-20230918203024459](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918203024459.png)

#### 大数据涉及的关键技术

![image-20230918203040453](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918203040453.png)

### 金融大数据

金融数据：一般具有“流数据”特征，需要在短时间内快速处理。

具有逻辑关系紧密，处理实时性要求高，可展示性需求强等特征。

* 数据分析技术：数据挖掘，机器学习等AI技术
* 数据管理技术：关系型和非关系型数据管理、数据融合和集成技术、ETL等技术
* 数据处理技术：分布式计算，内存计算，流处理技术等
* 数据展示技术：可视化技术、历史流展示技术、空间信息流展示技术等。

## CH2 并行计算技术

### 如何提高计算机性能？

为什么要并行计算技术？为了提高计算机性能！

* 提高处理器字长
* 提高集成度（限制：摩尔定律）
* 流水线等微体系结构技术
* 提高处理器频率

但是存在以下问题，导致单核处理器性能提升接近极限：

* VLSI集成度不可能无限制提高
* 处理器的指令级并行度提升接近极限（ILP墙）
* 处理器速度和存储器速度差异越来越大（CPU约为1ns，而主存约为100ns）
* 功耗和散热大幅增加超过芯片承受能力

### 并行计算技术的发展趋势和影响

* 越来越多的研究和应用领域需要使用并行计算技术

	* 并行计算技术将渗透到每个计算应用领域，尤其是涉及到大规模数据和复杂计算的应用领域

* 并行计算技术将对传统计算技术产生革命性的影响

	* 并行计算技术将影响传统计算技术的各个层面，与传统计算技术相互结合产生很多新的研究热点和课题
	* 很多传统的串行算法和计算方法都将需要重新研究和设计其并行化算法和计算方法

### 并行计算技术的分类

![image-20230918204013792](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204013792.png)

#### 弗林分类

![image-20230918204102025](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204102025.png)

![image-20230918204042637](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204042637.png)

#### 并行类型分类

![image-20230918204123431](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204123431.png)

#### 存储访问结构分类

![image-20230918204135426](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204135426.png)

#### 系统类型分类

![image-20230918204146473](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204146473.png)

![image-20230918204245145](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204245145.png)

![image-20230918204254576](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204254576.png)

#### 计算特征分类

![image-20230918204304001](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204304001.png)

#### 并行程序设计模型/方法分类

![image-20230918204320137](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204320137.png)

#### 发展趋势

![image-20230918204816521](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204816521.png)

### 并行计算主要技术问题

#### 多核/多处理器网络互联结构技术

![image-20230918210121018](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918210121018.png)

#### 存储访问体系结构

![image-20230918213547843](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213547843.png)

#### 分布式数据与文件管理

![image-20230918213558993](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213558993.png)

#### 并行计算任务的分解与算法设计

![image-20230918213607258](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213607258.png)

#### 并行程序设计模型和方法

![image-20230918213619916](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213619916.png)

![image-20230918213624978](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213624978.png)

#### 数据同步访问和通信控制

![image-20230918213634694](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213634694.png)

#### 可靠性设计与容错技术

![image-20230918213641126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213641126.png)

#### 并行计算软件框架平台

![image-20230918213653843](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213653843.png)

#### 系统性能评估和程序并行度评估

![image-20230918213702207](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213702207.png)

![image-20230918213711778](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213711778.png)

### MPI并行程序设计

#### MPI是什么？

MPI (Message Passing Interface)，基于消息传递的高性能并行计算编程接口。MPI在处理器间以消息传递方式进行数据通信和同步，以库函数形式为程序员提供了一组易于使用的编程接口。

特点：提供可靠的、面向消息的通信；在高性能科学计算领域广泛使用，适合于处理计算密集型的科学计算；独立于语言的编程规范，可移植性好。

#### MPI并行程序设计的时候需要注意什么？

* 消息传递并行程序设计

	* 用户必须通过显式地发送和接收消息来实现处理机间的数据交换。

	* 每个并行进程均有自己独立的地址空间，相互之间访问不能直接进行，必须通过显式的消息传递来实现。

* 并行计算粒度大，特别适合于大规模可扩展并行算法

	* 要求用户很好地分解问题，组织不同进程间的数据交换，并行计算粒度大。

#### MPI主要功能（通信方式）

* 用常规语言编程方式，所有节点运行同一个程序，但处理不同的数据

	* 提供点对点通信(Point-point communication)

	* 提供同步通信功能（阻塞通信）

	* 提供异步通信功能（非阻塞通信）

* 提供节点集合通信(Collective communication)

	* 提供一对多的广播通信

	* 提供多节点计算同步控制

	* 提供对结果的规约(Reduce)计算功能

* 提供用户自定义的复合数据类型传输

方式及相关接口整理如下：

MPI提供三大类通信方式：

* 点对点通信
  * 同步通信：阻塞式通信，等待通信操作完成后才返回。
    * *MPI_Send (buf, count, datatype, dest, tag, comm)* : 发送一个消息
    * *MPI_Recv (buf, count, datatype, source, tag, comm, status)* : 接受消息
  * 异步通信：非阻塞式通信，不等待通信操作完成即返回。
    *  *MPI_ISend (buf, count, datatype, dest, tag, comm, request)* : 异步发送
    * *MPI_IRecv (buf, count, datatype, source, tag, comm, status, request)* 异步接受消息
    * *MPI_Wait (request, status)* : 等待非阻塞数据传输完成
    * *MPI_Test (request, flag, status)* : 检查是否异步数据传输确实完成
* 节点集合通信
  * 一对多的广播通信。主要有以下接口：
    * *MPI_BCAST*: 一对多的广播式发送
  * 多节点计算同步控制。主要有以下接口：
    * *MPI_GATHER*：多个进程的消息以某种次序收集到一个进程
    * *MPI_SCATTER*：将一个信息划分为等长的段依次发送给其它进程
  * 对结果的规约（Reduce）计算功能
    * *MPI_Reduce*：将一组进程的数据按照指定的操作方式规约到一起并传送给一个进程
* 用户自定义的复合数据类型传输

#### MPI程序

##### MPI基本程序结构

![image-20230918215212360](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215212360.png)

##### MPI并行程序设计接口

![image-20230918215255309](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215255309.png)

![image-20230918215301625](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215301625.png)

![image-20230918215443383](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215443383.png)

![image-20230918215447655](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215447655.png)

##### MPI编程示例

![image-20230918215456069](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215456069.png)

![image-20230918215508951](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215508951.png)

![image-20230918215516128](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215516128.png)

![image-20230918215520244](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215520244.png)

![image-20230918215523816](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215523816.png)

![image-20230918215527512](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215527512.png)

![image-20230918215531278](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215531278.png)

#### 节点集合通信接口

提供一个进程与多个进程间同时通信的功能。

![image-20230918215554628](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215554628.png)

##### 集合通信功能

* ![image-20230918215838357](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215838357.png)

##### 数据规约操作

![image-20230918215831126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215831126.png)

![image-20230918220017793](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220017793.png)

![image-20230918220021991](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220021991.png)

![image-20230918220027955](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220027955.png)

#### MPI特点和不足

* **MPI的特点**
	* 灵活性好，适合于各种计算密集型的并行计算任务
	* 独立于语言的编程规范，可移植性好
	* 有很多开放机构或厂商实现并支持
* **MPI的不足**
	* 无良好的数据和任务划分支持
	* 缺少分布文件系统支持分布数据存储管理
	* 通信开销大，当计算问题复杂、节点数量很大时，难以处理，性能大幅下降
	* 无节点失效恢复机制，一旦有节点失效，可能导致计算过程无效
	* 缺少良好的构架支撑，程序员需要考虑以上所有细节问题，程序设计较为复杂

## CH3 MapReduce简介

### MapReduce的基本模型和处理思想

#### 三大设计思想

* **分而治之：处理大数据**

  对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取**分而治之**的策略。

* **并行抽象模型：Mapper与Reducer**

  MPI等并行计算方法缺少高层并行编程模型，为了克服这一缺陷，MapReduce借鉴了Lisp函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。

* **统一构架，隐藏系统层细节**

  MPI等并行计算方法缺少统一的计算框架支持，程序员需要考虑数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此，MapReduce设计并提供了统一的计算框架，为程序员隐藏了绝大多数系统层面的处理细节。

#### 分而治之：处理大数据

对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取**分而治之**的策略。

**不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算！**

并行化计算示例：

![image-20230925150338530](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150338530.png)

![image-20230925150344063](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150344063.png)

![image-20230925150400486](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150400486.png)

概念：

* Master：负责划分和分配任务
* Worker：负责数据块计算

#### 构建抽象模型：Mapper与Reducer

##### Map和Reduce的工作方式

MapReduce借鉴了**函数式设计语言Lisp**的设计思想。

* Lisp定义了可对列表元素进行整体处理的各种操作，如：
  * (add #(1 2 3 4) #(4 3 2 1)) 将产生结果： #(5 5 5 5)

* Lisp中也提供了类似于Map和Reduce的操作

  * 如: (**map** ’vector #+#(1 2 3 4 5) #(10 11 12 13 14)) 

  * 通过定义加法map运算将2个向量相加产生结果#(11 13 15 17 19)

    (**reduce** #’+#(11 13 15 17 19)) 通过加法归并产生累加结果75

![image-20230925151537434](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151537434.png)

**Map: 对一组数据元素进行某种重复式的处理**

**Reduce: 对Map的中间结果进行某种进一步的结果整理**

![image-20230925151556758](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151556758.png)

示例：

![image-20230925151149013](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151149013.png)

##### Map和Reduce操作的抽象描述

![image-20230925151926611](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151926611.png)

##### 基于Map和Reduce的并行计算模型

![image-20230925152049032](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152049032.png)

* 各个map函数对所划分的数据并行处理，从不同的输入数据产生不同的中间结果输出。

* 各个reduce也各自并行计算，各自负责处理不同的中间结果数据集合。

* 进行reduce处理之前，必须等到所有的map函数做完，因此，在进入reduce前需要有一个同步障(barrier)；这个阶段也负责对map的中间结果数据进行收集整理(aggregation & shuffle)处理，以便reduce更有效地计算最终结果。

* 最终汇总所有reduce的输出结果即可获得最终结果。

##### 如何提供统一的计算框架

MapReduce提供一个统一的计算框架，可完成：

* 计算任务的划分和调度

* 数据的分布存储和划分

* 处理数据与计算任务的同步

* 结果数据的收集整理(sorting, combining, partitioning…)

* 系统通信、负载平衡、计算性能优化处理

* 处理系统节点出错检测和失效恢复

##### MapReduce最大的亮点

**通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了**，为程序员提供一个抽象和高层的编程接口和框架。

程序员仅需要关心其应用层的具体计算问题，**仅需编写少量的处理应用本身计算问题的程序代码。**

如何具体完成这个并行计算任务所相关的诸多**系统层细节被隐藏起来，交给计算框架去处理**：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用。

##### *MapReduce提供的主要功能

MapReduce有四大主要功能：

* **数据划分和计算任务调度**

  提交的一个计算作业（Job)将被划分为很多个计算任务（Tasks)。

  任务调度功能主要负责为这些划分后的计算任务分配和调度计算结点（Map 结点或 Reduce 结点），同时负责监控这些结点的执行状态，以及 Map 结点执行的同步控制，也负责进行一些计算性能优化处理。例如，对最慢的计算任务采用多备份执行，选最快完成者作为结果。

* **数据/程序互定位**

  为了减少数据通信量，一个基本原则是本地化数据处理，即一个计算结点尽可能处理其本地磁盘上分布存储的数据，这实现了代码向数据的迁移。

  当无法进行这种本地化数据处理时，再寻找其他可用结点并将数据从网络上传送给该结点（数据向代码迁移)，但将尽可能从数据所在的本地机架上寻找可用结点以减少通信延迟。

* **出错处理**

  在以低端商用服务器构成的大规模 MapReduce 计算集群中，结点硬件（主机、兹盘、内存等）出错和软件有缺陷是常态。因此，MapReduce 架构需要能检测并隔离出错结点，并调度分配新的结点接管出错结点的计算任务。

* **分布式数据存储与文件管理**

  海量数据处理需要一个良好的分布数据存储和文件管理系统作为支撑，该系统能够把海量数据分布存储在各个结点的本地磁盘上，但保持整个数据在逻辑上成为一个完整的数据文件。

  为了提供数据存储容错机制，该系统还要提供数据块的多备份存储管理能力。

* **Combiner 和 Partitioner**

  为了减少数据通信开销，中间结果数据进入 Reduce 结点前需要进行合并（Combine）处理，即把具有同样主键的数据合并到一起避免重复传送。

  一个 Reduce 结点所处理的数据可能会来自多个 Map 结点，因此，Map 结点输出的中间结果需使用一定的策略进行适当的划分（Partition）处理，保证相关数据发送到同一个Reduce结点上。

#### 自动并行化并隐藏系统层细节

![image-20230925152844126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152844126.png)

![image-20230925152848119](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152848119.png)

### MapReduce的主要思想和特征

#### 向“外”横向扩展，而非向“上”纵向扩展

![image-20230925153231150](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153231150.png)

#### 失效被认为是常态

![image-20230925153237534](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153237534.png)

#### 把处理向数据迁移

![image-20230925153244540](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153244540.png)

#### 顺序处理数据、避免随机访问数据

![image-20230925153251146](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153251146.png)

#### 为应用开发者隐藏系统层细节

![image-20230925153328951](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153328951.png)

#### 平滑无缝的可扩展性

![image-20230925153337104](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153337104.png)

## CH4 Google MapReduce基本架构

回顾一下Google的三驾马车：GFS、MapReduce、Bigtable

![image-20230925153542156](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153542156.png)

### Google MapReduce的基本工作原理

#### Google MapReduce并行处理的基本过程

![image-20230925153919653](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153919653.png)

![image-20230925153926333](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153926333.png)

![image-20230925153933224](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153933224.png)

![image-20230925153937897](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153937897.png)

![image-20230925153942367](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153942367.png)

#### 失效处理

* 主节点失效

  * 主节点中会周期性地设置检查点(checkpoint)，检查整个计算作业的执行情况，一旦某个任务失效，可以从最近有效的检查点开始重新执行，避免从头开始计算的时间浪费。

  * 如果只有一个Master，它不太可能失败；因此，如果Master失败，将中止MapReduce计算。


* 工作节点失效
  * 工作节点失效是很普遍发生的，主节点会周期性地给工作节点发送检测命令，如果工作节点没有回应，这认为该工作节点失效，主节点将终止该工作节点的任务并把失效的任务重新调度到其它工作节点上重新执行。


#### 带宽优化

* 问题

	* 大量的键值对数据在传送给Reduce节点时会引起较大的通信带宽开销。

* 解决方案

	* 每个Map节点处理完成的中间键值对将由combiner做一个合并压缩，即把那些键名相同的键值对归并为一个键名下的一组数值。

![image-20230925154222696](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925154222696.png)

#### 计算优化

* **问题**
	* Reduce节点必须要等到所有Map节点计算结束才能开始执行，因此，如果有一个计算量大、或者由于某个问题导致很慢结束的Map节点，则会成为严重的“拖后腿者”。
	
* **解决方案**
* 把一个Map计算任务让多个Map节点同时做，取最快完成者的计算结果。

#### 用数据分区解决数据相关性问题

* **问题**
  * 一个Reduce节点上的计算数据可能会来自多个Map节点，因此，为了在进入Reduce节点计算之前，需要把属于一个Reduce节点的数据归并到一起。


* **解决方案**

  * 在Map阶段进行了Combining以后，可以根据一定的策略对Map输出的中间结果进行分区(partitioning)，这样即可解决以上数据相关性问题避免Reduce计算过程中的数据通信。

  例如：有一个巨大的数组，其最终结果需要排序，每个Map节点数据处理好后，为了避免在每个Reduce节点本地排序完成后还需要进行全局排序，我们可以使用一个分区策略如:(d%R)，d为数据大小，R为Reduce节点的个数，则可根据数据的大小将其划分到指定数据范围的Reduce节点上，每个Reduce将本地数据排好序后即为最终结果。


### 分布式文件系统GFS的工作原理

#### GPS是什么？

Google GFS是一个基于分布式集群的大型分布式文件系统，为MapReduce计算框架提供数据存储和数据可靠性支撑；

GFS是一个构建在分布节点本地文件系统之上的一个逻辑上文件系统，它将数据存储在物理上分布的每个节点上，但通过GFS将整个数据形成一个逻辑上整体的文件。

#### Google GFS的基本设计原则

* **廉价本地磁盘分布存储**
  * 各节点本地分布式存储数据，优点是不需要采用价格较贵的集中式磁盘阵列，容量可随节点数增加自动增加

* **多数据自动备份解决可靠性**
  * 采用廉价的普通磁盘，把磁盘数据出错视为常态，用自动多数据备份存储解决数据存储可靠性问题


* **为上层的MapReduce计算框架提供支撑**
  * GFS作为向上层MapReduce执行框架的底层数据存储支撑，负责处理所有的数据自动存储和容错处理，因而上层框架不需要考虑底层的数据存储和数据容错问题


#### Google GFS的基本架构和工作原理

##### 基本架构

![image-20230925155258227](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155258227.png)

###### GFS Master

![image-20230925155343542](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155343542.png)

###### GFS ChunkServer

![image-20230925155418509](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155418509.png)

##### 工作原理：数据访问工作过程

1. 在程序运行前，数据已经存储在GFS文件系统中；程序运行时应用程序会告诉GFS Server所要访问的文件名或者数据块索引是什么。

   ![image-20230925143810439](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143810439.png)

2. GFS Server根据文件名和数据块索引在其文件目录空间中查找和定位该文件或数据块，找出数据块具体在哪些ChunkServer上；将这些位置信息回送给应用程序。

   ![image-20230925143831698](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143831698.png)

3. 应用程序根据GFS Server返回的具体Chunk数据块位置信息，直接访问相应的ChunkServer。

   ![image-20230925143855037](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143855037.png)

4. 应用程序根据GFS Server返回的具体Chunk数据块位置信息直接读取指定位置的数据进行计算处理。

   ![image-20230925143908898](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143908898.png)

以上过程的特点是：应用程序访问具体数据的时候不需要经过GFS Master，避免了Master成为访问性能瓶颈；另一方面，由于大量数据会存储在不同的ChunkServer中，应用可实现并发访问。

##### GFS的系统管理技术

* **大规模集群安装技术**：如何在一个成千上万个节点的集群上迅速部署GFS，升级管理和维护等。

* 故障检测技术：GFS是构建在不可靠的廉价计算机之上的文件系统，节点数多，故障频繁，如何快速检测、定位、恢复或隔离故障节点。

* **节点动态加入技术**：当新的节点加入时，需要能自动安装和部署GFS。

* **节能技术**：服务器的耗电成本大于购买成本，Google为每个节点服务器配置了蓄电池替代UPS，大大节省了能耗。

### 分布式结构化数据表BigTable的基本工作原理

#### BigTable的基本作用和设计思想

![image-20230925160241919](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160241919.png)

GPS是一个分布式文件管理系统，不适合用来存储和管理结构化数据。因此在GFS之上又设计了一个结构化数据存储和访问管理系统—BigTable，为应用程序提供比单纯的文件系统更方便、更高层的数据操作能力，同时提供了一定粒度的结构化数据操作能力。

**但是它结构化粒度低，没有事务处理能力，因此不是真正意义上的数据库。**

#### BigTable的设计动机和目标

* 广泛的适用性：为一系列服务和应用而设计的数据存储系统，可满足对不同类型数据的存储和操作需求

* 很强的可扩展性：根据需要可随时自动加入或撤销服务器节点

* 高吞吐量数据访问：提供P级数据存储能力，每秒数百万次的访问请求

* 高可用性和容错性：保证系统在各种情况下都能正常运转，服务不中断

* 自动管理能力：自动加入和撤销服务器，自动负载平衡

* 简单性：系统设计尽量简单以减少复杂性和出错率

#### BigTable数据模型

BigTable主要是一个分布式多维表，表中的数据通过：

* 一个行关键字（row key）

* 一个列关键字（column key）

* 一个时间戳（timestamp）

进行索引和查询定位的。

BigTable对存储在表中的数据不做任何解释，一律视为字节串，具体数据结构的实现由用户自行定义。

BigTable查询模型

* (row:string, column:string,time:int64)->结果数据字节串

* 支持查询、插入和删除操作

![image-20230925145049058](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145049058.png)

BigTable数据存储格式：

* 行(Row):大小不超过64KB的任意字符串。表中的数据都是根据行关键字进行排序的。

  com.cnn.www就是一个行关键字，指明一行存储数据。URL地址倒排好处是：1)同一地址的网页将被存储在表中连续的位置，便于查找；2)倒排便于数据压缩，可大幅提高数据压缩率。

* 子表(Tablet)：一个大表可能太大，不利于存储管理，将在水平方向上被分为多个子表。

  ![image-20230925145235130](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145235130.png)

* 列(Column): BigTable将列关键字组织成为“列族”(column family)，每个族中的数据属于同一类别，如anchor是一个列族，其下可有不同的表示一个个超链的列关键字。一个列族下的数据会被压缩在一起存放（按列存放）。因此，一个列关键字可表示为： 族名：列名(family:qualifier)

  content、anchor都是族名；而cnnsi.com和my.look.ca则是anchor族中的列名。

  ![image-20230925145449795](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145449795.png)

* 时间戳(time stamp):很多时候同一个URL的网页会不断更新，而Google需要保存不同时间的网页数据，因此需要使用时间戳来加以区分。

  为了简化不同版本的数据管理，BigTable提供给了两种设置：

  * 保留最近的n个版本数据
  * 保留限定时间内的所有不同版本数据

  ![image-20230925145607139](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145607139.png)

#### BigTable基本架构

![image-20230925160602703](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160602703.png)

![image-20230925160613301](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160613301.png)

![image-20230925160617337](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160617337.png)

![image-20230925160621832](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160621832.png)

![image-20230925160703085](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160703085.png)

![image-20230925160707450](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160707450.png)

## CH5 Hadoop基本架构

### Hadoop平台的基本组成与生态系统

Hadoop是一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构。

Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中。

Hadoop的核心是分布式文件系统HDFS（Hadoop Distributed File System）和MapReduce。

#### Hadoop特性

可靠、高效、可伸缩

* 高可靠性
* 高效性
* 高可扩展性
* 高容错性
* 成本低
* 运行在Linux平台上

* 支持多种编程语言

#### 基本组成与生态系统

![image-20231013082107625](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013082107625.png)

![image-20231013082135903](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013082135903.png)

![image-20231013082147800](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013082147800.png)

### 分布式文件系统HDFS

HDFS模仿Google GFS设计实现。

#### HDFS基本特征

* 存储极大数目的信息/极大的单个文件
* 提供数据的高可靠性和容错能力
* 提供对数据的快速访问
* ……

#### HDFS基本构架

![image-20231013082637528](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013082637528.png)

HDFS的主要组件有NameNode，DataNode。

![image-20231013082758182](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013082758182.png)

用一个表来直观展示它们的功能：

| NameNode                                | DataNode                                   |
| --------------------------------------- | ------------------------------------------ |
| 存储元数据                              | 存储文件内容                               |
| 元数据保存在内存中                      | 文件内容保存在磁盘                         |
| 保存文件，block，datanode之间的映射关系 | 维护了block id到datanode本地文件的映射关系 |

NameNode充当了HDFS的主节点，负责元数据管理，DataNode充当了多个从节点，负责数据的存储和处理，而SecondaryNameNode是辅助节点，用于辅助主要的NameNode在元数据管理方面。这种架构模式有助于实现HDFS的可伸缩性、容错性和负载均衡。

##### NameNode

这是NameNode的目录结构：

![image-20231009234817222](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231009234817222.png)

在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），记录了每个文件中各个块所在的数据节点的位置信息，**保存了两个核心的数据结构，即FsImage和EditLog。**其中：

* **FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据**。

  FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示。

* **操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作**

###### 启动过程

* 在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。
* 一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件。
* 名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新。

###### 名称节点运行期间EditLog不断变大的问题

**在名称节点运行期间，HDFS的所有更新操作都是直接写到EditLog中，久而久之， EditLog文件将会变得很大。**

虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内HDFS系统处于安全模式，一直无法对外提供写操作，影响了用户的使用。

##### SecondaryNameNode

SecondaryNameNode本质上是NameNode的备份，NameNode也可以看作是FirstNameNode。

SecondaryNameNode的目录结构：

![image-20231009235420268](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231009235420268.png)

SecondaryNameNode是HDFS架构中的一个组成部分，**它是用来保存名称节点（NameNode）中对HDFS元数据信息的备份**，并减少名称节点重启的时间。SecondaryNameNode一般是单独运行在一台机器上。

工作流程：

* SecondaryNameNode会定期和NameNode通信
* 从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下
* 执行EditLog和FsImage文件合并
* 将新的FsImage文件发送到NameNode节点上
* NameNode使用新的FsImage和EditLog（缩小了）

![image-20231009235755198](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231009235755198.png)

第二名称节点用途：

* 不是热备份
* **主要是防止日志文件EditLog过大，导致名称节点失败恢复时消耗过多时间**（主要）
* 附带起到冷备份功能

#### HDFS命名空间管理

HDFS的命名空间包含目录、文件和块。

在HDFS1.0体系结构中，在整个HDFS集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个命名空间进行管理。

HDFS使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等。

#### HDFS通信协议

所有的HDFS通信协议都是构建在TCP/IP协议基础之上的。

客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互。

名称节点和数据节点之间则使用数据节点协议进行交互。

客户端与数据节点的交互是通过RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。

#### HDFS数据存取

![image-20231013084002400](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084002400.png)

![image-20231013084040967](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084040967.png)

##### 数据存放

* 第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点
* 第二个副本：放置在与第一个副本不同的机架的节点上
* 第三个副本：与第一个副本相同机架的其他节点上
* 更多副本：随机节点

##### 数据读取

HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API获取自己所属的机架ID（Rack Awareness）。

当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，**当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据**，如果没有发现，就随机选择一个副本读取数据。

![image-20231013084406753](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084406753.png)

![image-20231013084418638](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084418638.png)

![image-20231013084651717](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084651717.png)

![image-20231013084659657](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084659657.png)

#### HDFS可靠性与出错恢复

![image-20231013084720574](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013084720574.png)

##### NameNode出错

###### 备份（SecondaryNameNode）

对于NameNode，HDFS设置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和Editlog数据进行恢复。

###### 高可用性（HA）

HDFS HA（High Availability）是为了解决**单点故障**问题。

在Hadoop 2.x以后的版本中，HA集群设置两个名称节点，活跃（Active）和待命（Standby）。两种名称节点的状态同步，可以借助于一个共享存储系统来实现。一旦活跃名称节点出现故障，就可以立即切换到待命名称节点。

![image-20231010000905713](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231010000905713.png)

##### DataNode出错

###### 数据复制

HDFS会将每个文件的数据块在多个DataNode上进行复制存储，默认情况下，每个数据块会有三个副本。这样，即使某个DataNode发生故障，文件的数据仍然可以从其他DataNode上的副本中访问到。

###### 心跳检测

NameNode会定期向所有DataNode发送心跳信号，如果一段时间内没有收到某个DataNode的心跳信号，NameNode就会认为这个DataNode发生了故障，然后会将这个DataNode上的数据块的副本重新分配到其他DataNode上，以保证数据的可用性和可靠性。

###### 数据一致性和校验和（Checksum）

HDFS通过使用校验和来保证数据的一致性。

当数据写入HDFS时，会在客户端计算每个数据块的校验和，并将校验和和数据块一起存储在DataNode上。

当数据从HDFS读取时，会在客户端重新计算数据块的校验和，并与存储在DataNode上的校验和进行比较，如果两者不一致，说明数据在传输过程中可能发生了错误，客户端可以请求从其他DataNode上读取数据块的其他副本。

通过这种方式，HDFS可以在一定程度上保证数据的一致性和可靠性。

##### HDFS纠删码（EC）

EC，是一种编码容错技术。最早用于通信行业，数据传输中的数据恢复。它通过对数据进行分块，然后计算出校验数据，使得各个部分的数据产生关联性。**当一部分数据块丢失时，可以通过剩余的数据块和校验块计算出丢失的数据块。**

![image-20231013085131005](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013085131005.png)

![image-20231013085142838](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013085142838.png)

* 优势：节约存储空间
* 劣势：
  * 网络带宽的消耗，因为数据恢复需要去读其他的数据块和校验块
  * 进行编码，解码计算需要消耗CPU资源
* 最好的选择是用于冷数据集群
  * 冷数据集群往往有大量的长期没有被访问的数据，体量确实很大，采用EC技术，可以大大减少副本数
  * 冷数据集群基本稳定，耗资源量少，所以一旦进行数据恢复，将不会对集群造成大的影响


![image-20231013085336249](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013085336249.png)

![image-20231013085349401](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013085349401.png)

### YARN：新一代Hadoop架构

第二代Hadoop引入了YARN作为资源管理工具。

#### 理念

**YARN的目标就是实现“一个集群多个框架” ，即在一个集群上部署一个统一的资源调度管理框架YARN，在YARN之上可以部署其他各种计算框架。**

YARN的优势在于：

* 由YARN为这些计算框架提供统一的资源调度管理服务。
* 且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩。
* 可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率。
* 不同计算框架可以共享底层存储，避免了数据集跨集群移动。

YARN实现了：

* 更高的集群利用率，一个框架未使用的资源可由另一个框架进行使用，充分的避免资源浪费。
* 在新的Yarn中，通过加入ApplicationMaster是一个可变更的部分，用户可以针对不同的编程模型编写自己的ApplicationMaster，让更多的编程模型运行在Hadoop集群中。
* 在上一版框架中，JobTracker一个很大的负担就是监控Job的tasks运行情况，现在，这个部分下放到了ApplicationMaster中它的思路主要是：将原来的JobTracker三大功能拆分。

#### 实现方式

* Yet Another Resource Negotiator：另一种资源协调者。它是一个**通用资源管理系统，可为上层应用提供统一的资源管理和调度**，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。
* ResourceManager (RM）**全局管理所有应用程序计算资源的分配**，每个应用的ApplicationMaster (*AM*)负责相应的调度和协调。
* 一个应用程序无非是一个单独的传统的 MapReduce 任务或者是一个 DAG（有向无环图）任务。ResourceManager和每一台机器的节点管理服务器能够管理用户在那台机器上的进程并能对计算进行组织。

![image-20231010002116788](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231010002116788.png)

![image-20231010002127644](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231010002127644.png)

![image-20231010002153685](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231010002153685.png)

#### Hadoop MapReduce基本工作过程

![image-20231013085527475](https://repo-for-md.oss-cn-beijing.aliyuncs.com/uPic/image-20231013085527475.png)
